{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZJD011yhyWjD",
    "outputId": "35199005-d2bf-4120-bc5e-1e6fb8797d82"
   },
   "outputs": [],
   "source": [
    "# %pip install tensorflow==2.4.1\n",
    "# %pip install transformers\n",
    "# %pip install pyarrow\n",
    "# %pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oV5qIlEokph9"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "# import tensorflow_addons as tfa\n",
    "from math import ceil\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "# from transformers import RobertaTokenizer, RobertaTokenizerFast, TFRobertaModel, TFAlbertModel\n",
    "\n",
    "# AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_iteration = 'iteration_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9I2c4qh5FZa-"
   },
   "outputs": [],
   "source": [
    "with open(f\"./data/{model_iteration}/vocab/topics_vocab.pkl\", \"rb\") as f:\n",
    "    target_vocab = pickle.load(f)\n",
    "    \n",
    "target_vocab_inv = {j:i for i,j in target_vocab.items()}\n",
    "\n",
    "with open(f\"./data/{model_iteration}/vocab/doc_type_vocab.pkl\", \"rb\") as f:\n",
    "    doc_vocab = pickle.load(f)\n",
    "    \n",
    "doc_vocab_inv = {j:i for i,j in doc_vocab.items()}\n",
    "\n",
    "with open(f\"./data/{model_iteration}/vocab/journal_name_vocab.pkl\", \"rb\") as f:\n",
    "    journal_vocab = pickle.load(f)\n",
    "    \n",
    "journal_vocab_inv = {j:i for i,j in journal_vocab.items()}\n",
    "\n",
    "with open(f\"./data/{model_iteration}/vocab/paper_title_vocab.pkl\", \"rb\") as f:\n",
    "    title_vocab = pickle.load(f)\n",
    "    \n",
    "title_vocab_inv = {j:i for i,j in title_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65026"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282998"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Short code to create ID mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_ids = pd.read_parquet(\"fields_of_study_ids.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = tag_ids['normalized_name'].to_list()\n",
    "ids = tag_ids['field_of_study_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_id = {name:i for name, i in zip(names, ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_dict = {i:name_to_id[j] for i,j in target_vocab_inv.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65026"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"./data/{model_iteration}/vocab/tag_id_vocab.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(id_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./data/{model_iteration}/vocab/tag_id_vocab.pkl\", \"rb\") as f:\n",
    "    test_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8dvSQiNsFHr4"
   },
   "outputs": [],
   "source": [
    "encoding_layer = tf.keras.layers.experimental.preprocessing.CategoryEncoding(\n",
    "    max_tokens=len(target_vocab)+1, output_mode=\"binary\", sparse=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-16 14:58:35.749229: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-16 14:58:35.752527: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-16 14:58:35.752537: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-16 14:58:35.752552: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-31-169.ec2.internal): /proc/driver/nvidia/version does not exist\n",
      "2022-01-16 14:58:35.752730: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-16 14:58:35.752900: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "model_str = \"20220115_lr0006_beta025_gamma28_nH6_nL4_firstD2048_secondD1024_thirdD1024\"\n",
    "mag_model = tf.keras.models.load_model(f'./data/{model_iteration}/models/{model_str}/model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 64) dtype=int64 (created by layer 'paper_title_ids')>,\n",
       " <KerasTensor: shape=(None, 512) dtype=int64 (created by layer 'abstract_ids')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=int64 (created by layer 'doc_type_id')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=int64 (created by layer 'journal_id')>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mag_model.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = tf.keras.Model(inputs=mag_model.inputs, \n",
    "                             outputs=tf.math.top_k(mag_model.outputs, k=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "paper_title_ids (InputLayer)    [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "abstract_ids (InputLayer)       [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_embedding (Embedding)     multiple             18111936    paper_title_ids[0][0]            \n",
      "                                                                 abstract_ids[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 64, 64)       0           title_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 512, 64)      0           title_embedding[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_0/multiheadattent (None, 64, 64)       15604       tf.__operators__.add[0][0]       \n",
      "                                                                 tf.__operators__.add[0][0]       \n",
      "                                                                 tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_0/multiheadatt (None, 512, 64)      15604       tf.__operators__.add_1[0][0]     \n",
      "                                                                 tf.__operators__.add_1[0][0]     \n",
      "                                                                 tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_0/att_dropout (Dr (None, 64, 64)       0           title_encoder_0/multiheadattentio\n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_0/att_dropout  (None, 512, 64)      0           abstract_encoder_0/multiheadatten\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 64, 64)       0           tf.__operators__.add[0][0]       \n",
      "                                                                 title_encoder_0/att_dropout[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_10 (TFOpLa (None, 512, 64)      0           tf.__operators__.add_1[0][0]     \n",
      "                                                                 abstract_encoder_0/att_dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_0/att_layernormal (None, 64, 64)       128         tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_0/att_layernor (None, 512, 64)      128         tf.__operators__.add_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_0/ffn (Sequential (None, 64, 64)       132160      title_encoder_0/att_layernormaliz\n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_0/ffn (Sequent (None, 512, 64)      132160      abstract_encoder_0/att_layernorma\n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_0/ffn_dropout (Dr (None, 64, 64)       0           title_encoder_0/ffn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_0/ffn_dropout  (None, 512, 64)      0           abstract_encoder_0/ffn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 64, 64)       0           title_encoder_0/att_layernormaliz\n",
      "                                                                 title_encoder_0/ffn_dropout[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_11 (TFOpLa (None, 512, 64)      0           abstract_encoder_0/att_layernorma\n",
      "                                                                 abstract_encoder_0/ffn_dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_0/ffn_layernormal (None, 64, 64)       128         tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_0/ffn_layernor (None, 512, 64)      128         tf.__operators__.add_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_1/multiheadattent (None, 64, 64)       15604       title_encoder_0/ffn_layernormaliz\n",
      "                                                                 title_encoder_0/ffn_layernormaliz\n",
      "                                                                 title_encoder_0/ffn_layernormaliz\n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_1/multiheadatt (None, 512, 64)      15604       abstract_encoder_0/ffn_layernorma\n",
      "                                                                 abstract_encoder_0/ffn_layernorma\n",
      "                                                                 abstract_encoder_0/ffn_layernorma\n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_1/att_dropout (Dr (None, 64, 64)       0           title_encoder_1/multiheadattentio\n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_1/att_dropout  (None, 512, 64)      0           abstract_encoder_1/multiheadatten\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_4 (TFOpLam (None, 64, 64)       0           title_encoder_0/ffn_layernormaliz\n",
      "                                                                 title_encoder_1/att_dropout[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_12 (TFOpLa (None, 512, 64)      0           abstract_encoder_0/ffn_layernorma\n",
      "                                                                 abstract_encoder_1/att_dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_1/att_layernormal (None, 64, 64)       128         tf.__operators__.add_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_1/att_layernor (None, 512, 64)      128         tf.__operators__.add_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_1/ffn (Sequential (None, 64, 64)       132160      title_encoder_1/att_layernormaliz\n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_1/ffn (Sequent (None, 512, 64)      132160      abstract_encoder_1/att_layernorma\n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_1/ffn_dropout (Dr (None, 64, 64)       0           title_encoder_1/ffn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_1/ffn_dropout  (None, 512, 64)      0           abstract_encoder_1/ffn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_5 (TFOpLam (None, 64, 64)       0           title_encoder_1/att_layernormaliz\n",
      "                                                                 title_encoder_1/ffn_dropout[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_13 (TFOpLa (None, 512, 64)      0           abstract_encoder_1/att_layernorma\n",
      "                                                                 abstract_encoder_1/ffn_dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_1/ffn_layernormal (None, 64, 64)       128         tf.__operators__.add_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_1/ffn_layernor (None, 512, 64)      128         tf.__operators__.add_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_2/multiheadattent (None, 64, 64)       15604       title_encoder_1/ffn_layernormaliz\n",
      "                                                                 title_encoder_1/ffn_layernormaliz\n",
      "                                                                 title_encoder_1/ffn_layernormaliz\n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_2/multiheadatt (None, 512, 64)      15604       abstract_encoder_1/ffn_layernorma\n",
      "                                                                 abstract_encoder_1/ffn_layernorma\n",
      "                                                                 abstract_encoder_1/ffn_layernorma\n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_2/att_dropout (Dr (None, 64, 64)       0           title_encoder_2/multiheadattentio\n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_2/att_dropout  (None, 512, 64)      0           abstract_encoder_2/multiheadatten\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_6 (TFOpLam (None, 64, 64)       0           title_encoder_1/ffn_layernormaliz\n",
      "                                                                 title_encoder_2/att_dropout[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_14 (TFOpLa (None, 512, 64)      0           abstract_encoder_1/ffn_layernorma\n",
      "                                                                 abstract_encoder_2/att_dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_2/att_layernormal (None, 64, 64)       128         tf.__operators__.add_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_2/att_layernor (None, 512, 64)      128         tf.__operators__.add_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_2/ffn (Sequential (None, 64, 64)       132160      title_encoder_2/att_layernormaliz\n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_2/ffn (Sequent (None, 512, 64)      132160      abstract_encoder_2/att_layernorma\n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_2/ffn_dropout (Dr (None, 64, 64)       0           title_encoder_2/ffn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_2/ffn_dropout  (None, 512, 64)      0           abstract_encoder_2/ffn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_7 (TFOpLam (None, 64, 64)       0           title_encoder_2/att_layernormaliz\n",
      "                                                                 title_encoder_2/ffn_dropout[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_15 (TFOpLa (None, 512, 64)      0           abstract_encoder_2/att_layernorma\n",
      "                                                                 abstract_encoder_2/ffn_dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_2/ffn_layernormal (None, 64, 64)       128         tf.__operators__.add_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_2/ffn_layernor (None, 512, 64)      128         tf.__operators__.add_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_3/multiheadattent (None, 64, 64)       15604       title_encoder_2/ffn_layernormaliz\n",
      "                                                                 title_encoder_2/ffn_layernormaliz\n",
      "                                                                 title_encoder_2/ffn_layernormaliz\n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_3/multiheadatt (None, 512, 64)      15604       abstract_encoder_2/ffn_layernorma\n",
      "                                                                 abstract_encoder_2/ffn_layernorma\n",
      "                                                                 abstract_encoder_2/ffn_layernorma\n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_3/att_dropout (Dr (None, 64, 64)       0           title_encoder_3/multiheadattentio\n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_3/att_dropout  (None, 512, 64)      0           abstract_encoder_3/multiheadatten\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_8 (TFOpLam (None, 64, 64)       0           title_encoder_2/ffn_layernormaliz\n",
      "                                                                 title_encoder_3/att_dropout[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_16 (TFOpLa (None, 512, 64)      0           abstract_encoder_2/ffn_layernorma\n",
      "                                                                 abstract_encoder_3/att_dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_3/att_layernormal (None, 64, 64)       128         tf.__operators__.add_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_3/att_layernor (None, 512, 64)      128         tf.__operators__.add_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_3/ffn (Sequential (None, 64, 64)       132160      title_encoder_3/att_layernormaliz\n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_3/ffn (Sequent (None, 512, 64)      132160      abstract_encoder_3/att_layernorma\n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_3/ffn_dropout (Dr (None, 64, 64)       0           title_encoder_3/ffn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_3/ffn_dropout  (None, 512, 64)      0           abstract_encoder_3/ffn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "doc_type_id (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "journal_id (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_9 (TFOpLam (None, 64, 64)       0           title_encoder_3/att_layernormaliz\n",
      "                                                                 title_encoder_3/ffn_dropout[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_17 (TFOpLa (None, 512, 64)      0           abstract_encoder_3/att_layernorma\n",
      "                                                                 abstract_encoder_3/ffn_dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "doc_type_embedding (Embedding)  (None, 1, 64)        576         doc_type_id[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "journal_embedding (Embedding)   (None, 1, 64)        2877696     journal_id[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "title_encoder_3/ffn_layernormal (None, 64, 64)       128         tf.__operators__.add_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "abstract_encoder_3/ffn_layernor (None, 512, 64)      128         tf.__operators__.add_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (None, 1154, 64)     0           doc_type_embedding[0][0]         \n",
      "                                                                 journal_embedding[0][0]          \n",
      "                                                                 title_encoder_3/ffn_layernormaliz\n",
      "                                                                 abstract_encoder_3/ffn_layernorma\n",
      "                                                                 title_embedding[0][0]            \n",
      "                                                                 title_embedding[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1154, 2048)   133120      tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1154, 2048)   0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_norm_1 (LayerNormalizatio (None, 1154, 2048)   4096        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1154, 1024)   2098176     layer_norm_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1154, 1024)   0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_norm_2 (LayerNormalizatio (None, 1154, 1024)   2048        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "title_pooling_layer2 (GlobalAve (None, 1024)         0           layer_norm_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         1049600     title_pooling_layer2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_norm_3 (LayerNormalizatio (None, 1024)         2048        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cls (Dense)                     (None, 65027)        66652675    layer_norm_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.top_k (TFOpLambda)      TopKV2(values=(1, No 0           cls[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 92,116,131\n",
      "Trainable params: 92,116,131\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_model_predictions(data_path):\n",
    "    # Get all of the files, load into single pandas dataframe\n",
    "    # split up into blocks of 3000 and get model output\n",
    "    file_names = [x for x in os.listdir(data_path) if x.startswith('part')]\n",
    "    file_names.sort()\n",
    "    \n",
    "    full_df = pd.DataFrame()\n",
    "    \n",
    "    for file_name in file_names:\n",
    "        temp_df = pd.read_parquet(f\"{data_path}{file_name}\")\n",
    "        full_df = pd.concat([full_df, temp_df], axis=0)\n",
    "    \n",
    "    num_samples = 200\n",
    "    preds_final = []\n",
    "    scores_final = []\n",
    "    for i in range(ceil(full_df.shape[0]/num_samples)):\n",
    "        print(i)\n",
    "        small_df = full_df.iloc[i*num_samples:(i+1)*num_samples, :].copy()\n",
    "        preds, scores = get_model_predictions(small_df)\n",
    "        preds_final += preds\n",
    "        scores_final += scores\n",
    "    \n",
    "    full_df['predictions'] = preds_final\n",
    "    full_df['scores'] = scores_final\n",
    "    \n",
    "    return full_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_length(data, seq_len=512):\n",
    "    return data[:seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_predictions(input_data):\n",
    "    \n",
    "    input_data['paper_title_tok'] = input_data['paper_title_tok'].apply(cut_length, args=(64,))\n",
    "    input_data['abstract_tok'] = input_data['abstract_tok'].apply(cut_length, args=(256,))\n",
    "    \n",
    "    paper_title = tf.ragged.constant(input_data['paper_title_tok'].to_list()).to_tensor(shape=[None, 64])\n",
    "    abstract = tf.ragged.constant(input_data['abstract_tok'].to_list()).to_tensor(shape=[None, 512])\n",
    "    \n",
    "    doc_types = tf.convert_to_tensor(input_data['doc_type_tok'].to_list())\n",
    "    journal = tf.convert_to_tensor(input_data['journal_tok'].to_list())\n",
    "    \n",
    "    model_output = final_model([paper_title, abstract, doc_types, journal])\n",
    "    \n",
    "    scores = model_output.values.numpy()[0][:,:20].tolist()\n",
    "    preds = model_output.indices.numpy()[0][:,:20].tolist()\n",
    "    \n",
    "    return preds, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-16 14:58:55.657835: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1890713600 exceeds 10% of free system memory.\n",
      "2022-01-16 14:58:56.057342: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1890713600 exceeds 10% of free system memory.\n",
      "2022-01-16 14:58:56.358821: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1890713600 exceeds 10% of free system memory.\n",
      "2022-01-16 14:58:56.689733: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1890713600 exceeds 10% of free system memory.\n",
      "2022-01-16 14:58:57.080993: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1890713600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n"
     ]
    }
   ],
   "source": [
    "test_data = get_all_model_predictions(f\"./data/{model_iteration}/tokenized_data/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_parquet(f\"./data/{model_iteration}/test_data/predictions_{model_str}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = pd.read_parquet(f\"./{model_iteration}/test_data/data_with_predictions_500.parquet\")\n",
    "test_data['target_test'] = test_data['target_tok'].apply(lambda x: [i for i in x if i!=-1])\n",
    "test_data['target_test'] = test_data['target_test'].apply(len)\n",
    "test_data = test_data[test_data['target_test'] > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62517, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>doc_type_tok</th>\n",
       "      <th>journal_tok</th>\n",
       "      <th>target_tok</th>\n",
       "      <th>paper_title_tok</th>\n",
       "      <th>abstract_tok</th>\n",
       "      <th>predictions</th>\n",
       "      <th>scores</th>\n",
       "      <th>target_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10092</th>\n",
       "      <td>3137613306</td>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[8508]</td>\n",
       "      <td>[27095, 38898, 53383, 20052, 24275, 345, 21032...</td>\n",
       "      <td>[164026, 135830, 126699, 69677, 147160, 90684,...</td>\n",
       "      <td>[154201, 164026, 13523, 200157, 227992, 69677,...</td>\n",
       "      <td>[7648, 21032, 39153, 20052, 27095, 345, 24275,...</td>\n",
       "      <td>[0.9344683289527893, 0.8845618963241577, 0.587...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11968</th>\n",
       "      <td>2328757754</td>\n",
       "      <td>1991-04-01</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[26545]</td>\n",
       "      <td>[17473]</td>\n",
       "      <td>[63104, 58155, 1, 251476, 205881, 102709, 261898]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[55976, 17473, 1, 3350, 43340, 8580, 36274, 41...</td>\n",
       "      <td>[0.32550737261772156, 0.3008621335029602, 0.27...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8258</th>\n",
       "      <td>188905248</td>\n",
       "      <td>2009-11-21</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[31064, 1042, 55684, 58550, 27873, 3063, 52393...</td>\n",
       "      <td>[40425, 103381, 158348, 34791, 63104, 91400, 1...</td>\n",
       "      <td>[154201, 24097, 243294, 200157, 125250, 158348...</td>\n",
       "      <td>[677, 27873, 46396, 24292, 52393, 44252, 58550...</td>\n",
       "      <td>[0.7474294900894165, 0.6099224090576172, 0.605...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>3158607115</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[12127]</td>\n",
       "      <td>[2356, 39839, 55310, 45561, 43802, 46271, 2571...</td>\n",
       "      <td>[81755, 103336, 200157, 164023, 34691, 96256, ...</td>\n",
       "      <td>[256997, 245755, 45366, 155280, 239113, 198661...</td>\n",
       "      <td>[34450, 46271, 55310, 49166, 39839, 18515, 455...</td>\n",
       "      <td>[0.7110199928283691, 0.5690836310386658, 0.511...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>2083378874</td>\n",
       "      <td>2008-08-01</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[6281]</td>\n",
       "      <td>[57865, 17473, 43705, 24919, 24259, 2677, 8579...</td>\n",
       "      <td>[51254, 265955, 154201, 35470, 187763, 198756,...</td>\n",
       "      <td>[90696, 272442, 125955, 166690, 113843, 239113...</td>\n",
       "      <td>[24919, 57865, 17473, 2677, 18496, 8579, 57229...</td>\n",
       "      <td>[0.6942564845085144, 0.5798172950744629, 0.546...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         paper_id publication_date doc_type_tok journal_tok  \\\n",
       "10092  3137613306       2021-03-30          [3]      [8508]   \n",
       "11968  2328757754       1991-04-01          [3]     [26545]   \n",
       "8258    188905248       2009-11-21          [6]         [2]   \n",
       "2472   3158607115       2021-11-01          [3]     [12127]   \n",
       "4811   2083378874       2008-08-01          [3]      [6281]   \n",
       "\n",
       "                                              target_tok  \\\n",
       "10092  [27095, 38898, 53383, 20052, 24275, 345, 21032...   \n",
       "11968                                            [17473]   \n",
       "8258   [31064, 1042, 55684, 58550, 27873, 3063, 52393...   \n",
       "2472   [2356, 39839, 55310, 45561, 43802, 46271, 2571...   \n",
       "4811   [57865, 17473, 43705, 24919, 24259, 2677, 8579...   \n",
       "\n",
       "                                         paper_title_tok  \\\n",
       "10092  [164026, 135830, 126699, 69677, 147160, 90684,...   \n",
       "11968  [63104, 58155, 1, 251476, 205881, 102709, 261898]   \n",
       "8258   [40425, 103381, 158348, 34791, 63104, 91400, 1...   \n",
       "2472   [81755, 103336, 200157, 164023, 34691, 96256, ...   \n",
       "4811   [51254, 265955, 154201, 35470, 187763, 198756,...   \n",
       "\n",
       "                                            abstract_tok  \\\n",
       "10092  [154201, 164026, 13523, 200157, 227992, 69677,...   \n",
       "11968                                                [2]   \n",
       "8258   [154201, 24097, 243294, 200157, 125250, 158348...   \n",
       "2472   [256997, 245755, 45366, 155280, 239113, 198661...   \n",
       "4811   [90696, 272442, 125955, 166690, 113843, 239113...   \n",
       "\n",
       "                                             predictions  \\\n",
       "10092  [7648, 21032, 39153, 20052, 27095, 345, 24275,...   \n",
       "11968  [55976, 17473, 1, 3350, 43340, 8580, 36274, 41...   \n",
       "8258   [677, 27873, 46396, 24292, 52393, 44252, 58550...   \n",
       "2472   [34450, 46271, 55310, 49166, 39839, 18515, 455...   \n",
       "4811   [24919, 57865, 17473, 2677, 18496, 8579, 57229...   \n",
       "\n",
       "                                                  scores  target_test  \n",
       "10092  [0.9344683289527893, 0.8845618963241577, 0.587...           11  \n",
       "11968  [0.32550737261772156, 0.3008621335029602, 0.27...            1  \n",
       "8258   [0.7474294900894165, 0.6099224090576172, 0.605...           10  \n",
       "2472   [0.7110199928283691, 0.5690836310386658, 0.511...           10  \n",
       "4811   [0.6942564845085144, 0.5798172950744629, 0.546...           10  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Extra Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lang(x):\n",
    "    try:\n",
    "        lang = detect(x)\n",
    "    except:\n",
    "        lang = 'UNK'\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_data = pd.read_parquet(\"s3://mag-model-data/V2/raw_test_data/part-00000-tid-1178175042784182311-0b55b08b-d5db-4777-9e6a-572d293f915d-832-1-c000.snappy.parquet\") \\\n",
    ".rename(columns={\"topics\":\"topics_full\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62524 entries, 0 to 62523\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   paper_id          62524 non-null  int64  \n",
      " 1   doc_type          62524 non-null  object \n",
      " 2   original_title    62524 non-null  object \n",
      " 3   clean_title       62524 non-null  object \n",
      " 4   journal_name      54939 non-null  object \n",
      " 5   abstract_length   44073 non-null  float64\n",
      " 6   abstract          44073 non-null  object \n",
      " 7   clean_abstract    62524 non-null  object \n",
      " 8   topics_full       62524 non-null  object \n",
      " 9   publication_date  62524 non-null  object \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "extra_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_data['publication_date'] = pd.to_datetime(extra_data['publication_date'])\n",
    "extra_data['year'] = pd.DatetimeIndex(extra_data['publication_date']).year\n",
    "extra_data['month'] = pd.DatetimeIndex(extra_data['publication_date']).month\n",
    "extra_data['full_topic_len'] = extra_data['topics_full'].apply(lambda x: len(x))\n",
    "extra_data['lang'] = extra_data['clean_title'].apply(lambda x: get_lang(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62524 entries, 0 to 62523\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   paper_id          62524 non-null  int64         \n",
      " 1   doc_type          62524 non-null  object        \n",
      " 2   original_title    62524 non-null  object        \n",
      " 3   clean_title       62524 non-null  object        \n",
      " 4   journal_name      54939 non-null  object        \n",
      " 5   abstract_length   44073 non-null  float64       \n",
      " 6   abstract          44073 non-null  object        \n",
      " 7   clean_abstract    62524 non-null  object        \n",
      " 8   topics_full       62524 non-null  object        \n",
      " 9   publication_date  62524 non-null  datetime64[ns]\n",
      " 10  year              62524 non-null  int64         \n",
      " 11  month             62524 non-null  int64         \n",
      " 12  topic_len         62524 non-null  int64         \n",
      " 13  lang              62524 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(4), object(8)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "extra_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_data.rename(columns={'topic_len':'full_topic_len'}).to_parquet(\"extra_test_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "mag_model_baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
