{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZJD011yhyWjD",
    "outputId": "35199005-d2bf-4120-bc5e-1e6fb8797d82"
   },
   "outputs": [],
   "source": [
    "# %pip install tensorflow==2.4.1\n",
    "# %pip install transformers\n",
    "# %pip install pyarrow\n",
    "# %pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oV5qIlEokph9"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "# import tensorflow_addons as tfa\n",
    "from math import ceil\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "# from transformers import RobertaTokenizer, RobertaTokenizerFast, TFRobertaModel, TFAlbertModel\n",
    "\n",
    "# AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_iteration = 'iteration_final/basic_word_tokenized_500_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9I2c4qh5FZa-"
   },
   "outputs": [],
   "source": [
    "with open(f\"./{model_iteration}/vocab/topics_vocab.pkl\", \"rb\") as f:\n",
    "    target_vocab = pickle.load(f)\n",
    "    \n",
    "target_vocab_inv = {j:i for i,j in target_vocab.items()}\n",
    "\n",
    "with open(f\"./{model_iteration}/vocab/doc_type_vocab.pkl\", \"rb\") as f:\n",
    "    doc_vocab = pickle.load(f)\n",
    "    \n",
    "doc_vocab_inv = {j:i for i,j in doc_vocab.items()}\n",
    "\n",
    "with open(f\"./{model_iteration}/vocab/journal_name_vocab.pkl\", \"rb\") as f:\n",
    "    journal_vocab = pickle.load(f)\n",
    "    \n",
    "journal_vocab_inv = {j:i for i,j in journal_vocab.items()}\n",
    "\n",
    "with open(f\"./{model_iteration}/vocab/paper_title_vocab.pkl\", \"rb\") as f:\n",
    "    title_vocab = pickle.load(f)\n",
    "    \n",
    "title_vocab_inv = {j:i for i,j in title_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82178"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Short code to create ID mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_ids = pd.read_parquet(\"fields_of_study_ids.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = tag_ids['normalized_name'].to_list()\n",
    "ids = tag_ids['field_of_study_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_id = {name:i for name, i in zip(names, ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_dict = {i:name_to_id[j] for i,j in target_vocab_inv.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"./{model_iteration}/vocab/tag_id_vocab.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(id_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./{model_iteration}/vocab/tag_id_vocab.pkl\", \"rb\") as f:\n",
    "    test_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8dvSQiNsFHr4"
   },
   "outputs": [],
   "source": [
    "encoding_layer = tf.keras.layers.experimental.preprocessing.CategoryEncoding(\n",
    "    max_tokens=len(target_vocab)+1, output_mode=\"binary\", sparse=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177567"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82178"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 23:06:01.068679: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-25 23:06:01.077543: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "mag_model = tf.keras.models.load_model(f'./{model_iteration}/models/gamma_28_nH8_nL6_epoch25/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 64) dtype=int64 (created by layer 'paper_title_ids')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=int64 (created by layer 'doc_type_id')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=int64 (created by layer 'journal_id')>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mag_model.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = tf.keras.Model(inputs=mag_model.inputs, \n",
    "                             outputs=tf.math.top_k(mag_model.outputs, k=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "paper_title_ids (InputLayer)    [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_embedding (Embedding)     (None, 64, 512)      90914816    paper_title_ids[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 64, 512)      0           title_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_0/multiheadattention (M (None, 64, 512)      1050624     tf.__operators__.add[0][0]       \n",
      "                                                                 tf.__operators__.add[0][0]       \n",
      "                                                                 tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_0/att_dropout (Dropout) (None, 64, 512)      0           encoder_0/multiheadattention[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 64, 512)      0           tf.__operators__.add[0][0]       \n",
      "                                                                 encoder_0/att_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_0/att_layernormalizatio (None, 64, 512)      1024        tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "encoder_0/ffn (Sequential)      (None, 64, 512)      1050112     encoder_0/att_layernormalization[\n",
      "__________________________________________________________________________________________________\n",
      "encoder_0/ffn_dropout (Dropout) (None, 64, 512)      0           encoder_0/ffn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 64, 512)      0           encoder_0/att_layernormalization[\n",
      "                                                                 encoder_0/ffn_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_0/ffn_layernormalizatio (None, 64, 512)      1024        tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/multiheadattention (M (None, 64, 512)      1050624     encoder_0/ffn_layernormalization[\n",
      "                                                                 encoder_0/ffn_layernormalization[\n",
      "                                                                 encoder_0/ffn_layernormalization[\n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/att_dropout (Dropout) (None, 64, 512)      0           encoder_1/multiheadattention[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 64, 512)      0           encoder_0/ffn_layernormalization[\n",
      "                                                                 encoder_1/att_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/att_layernormalizatio (None, 64, 512)      1024        tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/ffn (Sequential)      (None, 64, 512)      1050112     encoder_1/att_layernormalization[\n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/ffn_dropout (Dropout) (None, 64, 512)      0           encoder_1/ffn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_4 (TFOpLam (None, 64, 512)      0           encoder_1/att_layernormalization[\n",
      "                                                                 encoder_1/ffn_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/ffn_layernormalizatio (None, 64, 512)      1024        tf.__operators__.add_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2/multiheadattention (M (None, 64, 512)      1050624     encoder_1/ffn_layernormalization[\n",
      "                                                                 encoder_1/ffn_layernormalization[\n",
      "                                                                 encoder_1/ffn_layernormalization[\n",
      "__________________________________________________________________________________________________\n",
      "encoder_2/att_dropout (Dropout) (None, 64, 512)      0           encoder_2/multiheadattention[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_5 (TFOpLam (None, 64, 512)      0           encoder_1/ffn_layernormalization[\n",
      "                                                                 encoder_2/att_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2/att_layernormalizatio (None, 64, 512)      1024        tf.__operators__.add_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2/ffn (Sequential)      (None, 64, 512)      1050112     encoder_2/att_layernormalization[\n",
      "__________________________________________________________________________________________________\n",
      "encoder_2/ffn_dropout (Dropout) (None, 64, 512)      0           encoder_2/ffn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_6 (TFOpLam (None, 64, 512)      0           encoder_2/att_layernormalization[\n",
      "                                                                 encoder_2/ffn_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2/ffn_layernormalizatio (None, 64, 512)      1024        tf.__operators__.add_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3/multiheadattention (M (None, 64, 512)      1050624     encoder_2/ffn_layernormalization[\n",
      "                                                                 encoder_2/ffn_layernormalization[\n",
      "                                                                 encoder_2/ffn_layernormalization[\n",
      "__________________________________________________________________________________________________\n",
      "encoder_3/att_dropout (Dropout) (None, 64, 512)      0           encoder_3/multiheadattention[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_7 (TFOpLam (None, 64, 512)      0           encoder_2/ffn_layernormalization[\n",
      "                                                                 encoder_3/att_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3/att_layernormalizatio (None, 64, 512)      1024        tf.__operators__.add_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3/ffn (Sequential)      (None, 64, 512)      1050112     encoder_3/att_layernormalization[\n",
      "__________________________________________________________________________________________________\n",
      "encoder_3/ffn_dropout (Dropout) (None, 64, 512)      0           encoder_3/ffn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_8 (TFOpLam (None, 64, 512)      0           encoder_3/att_layernormalization[\n",
      "                                                                 encoder_3/ffn_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3/ffn_layernormalizatio (None, 64, 512)      1024        tf.__operators__.add_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4/multiheadattention (M (None, 64, 512)      1050624     encoder_3/ffn_layernormalization[\n",
      "                                                                 encoder_3/ffn_layernormalization[\n",
      "                                                                 encoder_3/ffn_layernormalization[\n",
      "__________________________________________________________________________________________________\n",
      "encoder_4/att_dropout (Dropout) (None, 64, 512)      0           encoder_4/multiheadattention[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_9 (TFOpLam (None, 64, 512)      0           encoder_3/ffn_layernormalization[\n",
      "                                                                 encoder_4/att_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4/att_layernormalizatio (None, 64, 512)      1024        tf.__operators__.add_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4/ffn (Sequential)      (None, 64, 512)      1050112     encoder_4/att_layernormalization[\n",
      "__________________________________________________________________________________________________\n",
      "encoder_4/ffn_dropout (Dropout) (None, 64, 512)      0           encoder_4/ffn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_10 (TFOpLa (None, 64, 512)      0           encoder_4/att_layernormalization[\n",
      "                                                                 encoder_4/ffn_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4/ffn_layernormalizatio (None, 64, 512)      1024        tf.__operators__.add_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "encoder_5/multiheadattention (M (None, 64, 512)      1050624     encoder_4/ffn_layernormalization[\n",
      "                                                                 encoder_4/ffn_layernormalization[\n",
      "                                                                 encoder_4/ffn_layernormalization[\n",
      "__________________________________________________________________________________________________\n",
      "encoder_5/att_dropout (Dropout) (None, 64, 512)      0           encoder_5/multiheadattention[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_11 (TFOpLa (None, 64, 512)      0           encoder_4/ffn_layernormalization[\n",
      "                                                                 encoder_5/att_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_5/att_layernormalizatio (None, 64, 512)      1024        tf.__operators__.add_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "encoder_5/ffn (Sequential)      (None, 64, 512)      1050112     encoder_5/att_layernormalization[\n",
      "__________________________________________________________________________________________________\n",
      "encoder_5/ffn_dropout (Dropout) (None, 64, 512)      0           encoder_5/ffn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_12 (TFOpLa (None, 64, 512)      0           encoder_5/att_layernormalization[\n",
      "                                                                 encoder_5/ffn_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_5/ffn_layernormalizatio (None, 64, 512)      1024        tf.__operators__.add_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64, 2048)     1050624     encoder_5/ffn_layernormalization[\n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64, 1024)     525312      title_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 2048)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64, 1024)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "journal_id (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "doc_type_id (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer_norm_1 (LayerNormalizatio (None, 64, 2048)     4096        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_norm_2 (LayerNormalizatio (None, 64, 1024)     2048        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "journal_embedding (Embedding)   (None, 1, 64)        2739904     journal_id[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "doc_type_embedding (Embedding)  (None, 1, 32)        288         doc_type_id[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "title_pooling_layer (GlobalAver (None, 2048)         0           layer_norm_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "title_pooling_layer2 (GlobalAve (None, 1024)         0           layer_norm_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "journal_pooling_layer (GlobalAv (None, 64)           0           journal_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "doc_pooling_layer (GlobalAverag (None, 32)           0           doc_type_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (None, 3168)         0           title_pooling_layer[0][0]        \n",
      "                                                                 title_pooling_layer2[0][0]       \n",
      "                                                                 journal_pooling_layer[0][0]      \n",
      "                                                                 doc_pooling_layer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         3245056     tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_norm_3 (LayerNormalizatio (None, 1024)         2048        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cls (Dense)                     (None, 82179)        84233475    layer_norm_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.top_k (TFOpLambda)      TopKV2(values=(1, No 0           cls[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 195,334,371\n",
      "Trainable params: 195,334,371\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_model_predictions(data_path):\n",
    "    # Get all of the files, load into single pandas dataframe\n",
    "    # split up into blocks of 3000 and get model output\n",
    "    file_names = [x for x in os.listdir(f\"./{model_iteration}/tokenized_data/test/\") if x.startswith('part')]\n",
    "    file_names.sort()\n",
    "    \n",
    "    full_df = pd.DataFrame()\n",
    "    \n",
    "    for file_name in file_names:\n",
    "        temp_df = pd.read_parquet(f\"./{model_iteration}/tokenized_data/test/{file_name}\")\n",
    "        full_df = pd.concat([full_df, temp_df], axis=0)\n",
    "    \n",
    "    num_samples = 1000\n",
    "    preds_final = []\n",
    "    scores_final = []\n",
    "    for i in range(ceil(full_df.shape[0]/num_samples)):\n",
    "        print(i)\n",
    "        small_df = full_df.iloc[i*num_samples:(i+1)*num_samples, :].copy()\n",
    "        preds, scores = get_model_predictions(small_df)\n",
    "        preds_final += preds\n",
    "        scores_final += scores\n",
    "    \n",
    "    full_df['predictions'] = preds_final\n",
    "    full_df['scores'] = scores_final\n",
    "    \n",
    "    return full_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_predictions(input_data):\n",
    "    \n",
    "    paper_titles = tf.keras.preprocessing.sequence.pad_sequences(input_data['paper_title_tok'].to_list(), maxlen=64, \n",
    "                                                             dtype='int64', padding='post', \n",
    "                                                             truncating='post', value=0)\n",
    "    \n",
    "    doc_types = tf.convert_to_tensor(input_data['doc_type_tok'].to_list())\n",
    "    journal = tf.convert_to_tensor(input_data['journal_tok'].to_list())\n",
    "    \n",
    "    model_output = final_model([paper_titles, doc_types, journal])\n",
    "    \n",
    "    scores = model_output.values.numpy()[0][:,:20].tolist()\n",
    "    preds = model_output.indices.numpy()[0][:,:20].tolist()\n",
    "    \n",
    "    return preds, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n"
     ]
    }
   ],
   "source": [
    "test_data = get_all_model_predictions(f\"./{model_iteration}/tokenized_data/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_parquet(f\"./{model_iteration}/test_data/data_with_predictions_500_gamma28_nH8_nL6_epoch25.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = pd.read_parquet(f\"./{model_iteration}/test_data/data_with_predictions_500.parquet\")\n",
    "test_data['target_test'] = test_data['target_tok'].apply(lambda x: [i for i in x if i!=-1])\n",
    "test_data['target_test'] = test_data['target_test'].apply(len)\n",
    "test_data = test_data[test_data['target_test'] > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97233, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>doc_type_tok</th>\n",
       "      <th>journal_tok</th>\n",
       "      <th>target_tok</th>\n",
       "      <th>paper_title_tok</th>\n",
       "      <th>predictions</th>\n",
       "      <th>scores</th>\n",
       "      <th>target_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23907</th>\n",
       "      <td>3131361924</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[294]</td>\n",
       "      <td>[1715, 101, 2, 1381]</td>\n",
       "      <td>[168800, 166817, 107386, 126558, 151334, 17634...</td>\n",
       "      <td>[2, 1381, 42, 171, 37, 306, 156, 11791, 543, 1...</td>\n",
       "      <td>[0.641745388507843, 0.4675076901912689, 0.4003...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>2173313759</td>\n",
       "      <td>1971-12-01</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[2775]</td>\n",
       "      <td>[2076, 8, 2685, 49, 3770, 388, 239, 2736, 1524...</td>\n",
       "      <td>[161506, 64102, 37508, 126553, 97706, 151326, ...</td>\n",
       "      <td>[8, 49, 239, 95, 696, 2736, 2685, 685, 5727, 3...</td>\n",
       "      <td>[0.7249653339385986, 0.4582909345626831, 0.438...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4440</th>\n",
       "      <td>2357299977</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[1039]</td>\n",
       "      <td>[1425, 5, 328, 81, 691, 1835, 478, 586, 251, 8...</td>\n",
       "      <td>[35688, 633, 117665, 162290, 14251, 126553, 13...</td>\n",
       "      <td>[5, 8493, 586, 691, 328, 251, 623, 42, 397, 47...</td>\n",
       "      <td>[0.6601946353912354, 0.6510505080223083, 0.572...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8505</th>\n",
       "      <td>2747201174</td>\n",
       "      <td>2017-09-29</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[5623]</td>\n",
       "      <td>[61, 1, 38146, 443]</td>\n",
       "      <td>[103617, 14805, 112377, 131258, 152551, 150768...</td>\n",
       "      <td>[1, 6, 31, 2024, 38146, 2181, 61, 76, 85, 1967...</td>\n",
       "      <td>[0.9602290391921997, 0.5080435276031494, 0.466...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18728</th>\n",
       "      <td>3134951874</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[2384]</td>\n",
       "      <td>[774, 2, 37, 16104, 14212, 3972, 215, 4050, 79...</td>\n",
       "      <td>[100107, 17828, 126553, 53496, 133601, 166817,...</td>\n",
       "      <td>[79, 1708, 2, 774, 1139, 215, 14212, 44, 29434...</td>\n",
       "      <td>[0.8013430237770081, 0.688534677028656, 0.6055...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         paper_id publication_date doc_type_tok journal_tok  \\\n",
       "23907  3131361924       2021-07-01          [3]       [294]   \n",
       "1629   2173313759       1971-12-01          [3]      [2775]   \n",
       "4440   2357299977       2013-03-01          [3]      [1039]   \n",
       "8505   2747201174       2017-09-29          [3]      [5623]   \n",
       "18728  3134951874       2021-06-01          [3]      [2384]   \n",
       "\n",
       "                                              target_tok  \\\n",
       "23907                               [1715, 101, 2, 1381]   \n",
       "1629   [2076, 8, 2685, 49, 3770, 388, 239, 2736, 1524...   \n",
       "4440   [1425, 5, 328, 81, 691, 1835, 478, 586, 251, 8...   \n",
       "8505                                 [61, 1, 38146, 443]   \n",
       "18728  [774, 2, 37, 16104, 14212, 3972, 215, 4050, 79...   \n",
       "\n",
       "                                         paper_title_tok  \\\n",
       "23907  [168800, 166817, 107386, 126558, 151334, 17634...   \n",
       "1629   [161506, 64102, 37508, 126553, 97706, 151326, ...   \n",
       "4440   [35688, 633, 117665, 162290, 14251, 126553, 13...   \n",
       "8505   [103617, 14805, 112377, 131258, 152551, 150768...   \n",
       "18728  [100107, 17828, 126553, 53496, 133601, 166817,...   \n",
       "\n",
       "                                             predictions  \\\n",
       "23907  [2, 1381, 42, 171, 37, 306, 156, 11791, 543, 1...   \n",
       "1629   [8, 49, 239, 95, 696, 2736, 2685, 685, 5727, 3...   \n",
       "4440   [5, 8493, 586, 691, 328, 251, 623, 42, 397, 47...   \n",
       "8505   [1, 6, 31, 2024, 38146, 2181, 61, 76, 85, 1967...   \n",
       "18728  [79, 1708, 2, 774, 1139, 215, 14212, 44, 29434...   \n",
       "\n",
       "                                                  scores  target_test  \n",
       "23907  [0.641745388507843, 0.4675076901912689, 0.4003...            4  \n",
       "1629   [0.7249653339385986, 0.4582909345626831, 0.438...           10  \n",
       "4440   [0.6601946353912354, 0.6510505080223083, 0.572...           11  \n",
       "8505   [0.9602290391921997, 0.5080435276031494, 0.466...            4  \n",
       "18728  [0.8013430237770081, 0.688534677028656, 0.6055...           10  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_raw = pd.DataFrame()\n",
    "for i in os.listdir(\"./iteration_final/test_data_raw/\"):\n",
    "    if i.startswith('part'):\n",
    "        temp_df = pd.read_parquet(f\"./iteration_final/test_data_raw/{i}\")\n",
    "        test_data_raw = pd.concat([test_data_raw, temp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>doc_type</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>journal_name</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3155850838</td>\n",
       "      <td>Conference</td>\n",
       "      <td>counterfactual reward modification for streaming recommendation with delayed feedback</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-07-11</td>\n",
       "      <td>[computer science, counterfactual thinking, cognitive psychology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>3090874414</td>\n",
       "      <td>Patent</td>\n",
       "      <td>stably fixed rubber frame</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>[vertical edge, integrally closed, geometry, natural rubber, perpendicular, limiting, edge, physics, liquid crystal display, frame]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3094668390</td>\n",
       "      <td>Journal</td>\n",
       "      <td>applicability of magnetic resonance imaging of the knee in forensic age estimation</td>\n",
       "      <td>american journal of forensic medicine and pathology</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>[stage, magnetic resonance imaging, radiology, radiological weapon, ossification, age estimation, femoral epiphysis, forensic science, medicine, mri image]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>3098691962</td>\n",
       "      <td>Journal</td>\n",
       "      <td>crystal lattice properties fully determine short range interaction parameters for alkali and halide ions</td>\n",
       "      <td>journal of chemical physics</td>\n",
       "      <td>2012-08-09</td>\n",
       "      <td>[lennard jones potential, ion, lattice energy, materials science, lattice, lattice constant, aqueous solution, chemical physics, solvation, crystal structure]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2857720048</td>\n",
       "      <td>Patent</td>\n",
       "      <td>signal power lightning prevention box air switch state detecting system</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-11-24</td>\n",
       "      <td>[electricity, interface, power, signal, state, electrical engineering, logic gate, lightning, computer science, alarm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2240568383</td>\n",
       "      <td>Journal</td>\n",
       "      <td>ionic transport in high energy density matter</td>\n",
       "      <td>bulletin of the american physical society</td>\n",
       "      <td>2015-11-17</td>\n",
       "      <td>[boltzmann constant, coulomb, statistical physics, high energy density matter, thermal conductivity, yukawa potential, viscosity, molecular dynamics, physics, logarithm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1189781847</td>\n",
       "      <td>Thesis</td>\n",
       "      <td>pengaruh faktor faktor budaya organisasi terhadap kinerja karyawan pt wonokoyo jaya corporindo kantor pusat surabaya</td>\n",
       "      <td>None</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>[statistical significance, business administration, competence, employee performance, linear regression, operations management, competitive advantage, strategic management, engineering, teamwork, variables]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3118080385</td>\n",
       "      <td>Journal</td>\n",
       "      <td>differences in health seeking behaviors by socioeconomic groups among the pediatric hydrocephalus patient population</td>\n",
       "      <td>interdisciplinary neurosurgery</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>[pediatrics, medicine, socioeconomic status, vomiting, pediatric hydrocephalus, patient population, household income, hydrocephalus, health seeking, descriptive statistics]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1599508969</td>\n",
       "      <td>Journal</td>\n",
       "      <td>insuline bagimli diabetes mellituslu hastalarda hbaic ile serum insulin kolesterol ve trigliserit duzeyleri arasindaki iliski</td>\n",
       "      <td>turkiye klinikleri tip bilimleri dergisi</td>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>[medicine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2770440433</td>\n",
       "      <td>Thesis</td>\n",
       "      <td>comparative study of belt loop gastropexy and fundic gastropexy in dogs</td>\n",
       "      <td>None</td>\n",
       "      <td>1994-11-01</td>\n",
       "      <td>[gastropexy, mathematics, anatomy, null, loop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125853187</td>\n",
       "      <td>None</td>\n",
       "      <td>observations of split shear waves from young ocean crust</td>\n",
       "      <td>None</td>\n",
       "      <td>1991-01-01</td>\n",
       "      <td>[geophysics, ocean bottom seismometer, polarization, seismic anisotropy, shear waves, magnetosphere particle motion, oceanic crust, geology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3159121270</td>\n",
       "      <td>Journal</td>\n",
       "      <td>discussion of cylindrical central baffle flume for flow measurement in open channels by aniruddha d ghare ankur kapoor and avinash m badar</td>\n",
       "      <td>journal of irrigation and drainage engineering asce</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>[flume, baffle, geology, mechanics, flow measurement]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2985692745</td>\n",
       "      <td>Patent</td>\n",
       "      <td>liquid nitrogen refrigerator truck with thermoelectric power generation device</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>[thermoelectric generator, liquid nitrogen, pressure regulator, refrigerator car, exhaust gas, atmosphere, truck, waste management, nitrogen, materials science]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>3030261487</td>\n",
       "      <td>None</td>\n",
       "      <td>target delineation for radiosurgery including postoperative cavity radiosurgery in brain metastases</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>[radiology, computed tomography, contouring, mri techniques, radiation therapy, magnetic resonance imaging, spatial distortion, radiosurgery, medicine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>3128313991</td>\n",
       "      <td>Journal</td>\n",
       "      <td>maternal exposure to cooking smoke and risk of low birth weight in india</td>\n",
       "      <td>science of the total environment</td>\n",
       "      <td>2021-06-20</td>\n",
       "      <td>[family health, environmental health, smoke, cooking practices, medicine, low birth weight, birth weight, birth size]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2742374350</td>\n",
       "      <td>None</td>\n",
       "      <td>modification of silicone elastomer with zwitterionic silane for durable antifouling properties</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>[silicone, elastomer, silane, materials science, biofouling, composite material]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3152861079</td>\n",
       "      <td>Journal</td>\n",
       "      <td>fraxinellone alleviates kidney fibrosis by inhibiting cug binding protein 1 mediated fibroblast activation</td>\n",
       "      <td>toxicology and applied pharmacology</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>[kidney fibrosis, medicine, fraxinellone, pharmacology, cyclin dependent kinase, cug binding protein, kidney, fibroblast, kidney disease, p38 mitogen activated protein kinases]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>3038891449</td>\n",
       "      <td>Journal</td>\n",
       "      <td>study on anisotropic mechanical properties and failure modes of layered rock using uniaxial compression test</td>\n",
       "      <td>journal of testing and evaluation</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>[failure mode and effects analysis, ultimate tensile strength, composite material, bedding, materials science, shearing, compressive strength, magnetic dip, transverse isotropy, anisotropy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2337676554</td>\n",
       "      <td>Journal</td>\n",
       "      <td>development of octacalcium phosphate bone substitute material and its elucidation of osteoconductivity mechanism</td>\n",
       "      <td>frontiers in bioengineering and biotechnology</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>[biophysics, octacalcium phosphate, mechanism, chemistry, bone substitute]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>3091339658</td>\n",
       "      <td>Patent</td>\n",
       "      <td>magnetic stirring device for tissue dehydrator</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-05-05</td>\n",
       "      <td>[magnetic field, base, materials science, cylinder, bearing, composite material, magnet]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       paper_id    doc_type  \\\n",
       "57   3155850838  Conference   \n",
       "234  3090874414      Patent   \n",
       "0    3094668390     Journal   \n",
       "260  3098691962     Journal   \n",
       "191  2857720048      Patent   \n",
       "94   2240568383     Journal   \n",
       "19   1189781847      Thesis   \n",
       "39   3118080385     Journal   \n",
       "30   1599508969     Journal   \n",
       "113  2770440433      Thesis   \n",
       "4     125853187        None   \n",
       "1    3159121270     Journal   \n",
       "230  2985692745      Patent   \n",
       "251  3030261487        None   \n",
       "90   3128313991     Journal   \n",
       "170  2742374350        None   \n",
       "38   3152861079     Journal   \n",
       "78   3038891449     Journal   \n",
       "93   2337676554     Journal   \n",
       "276  3091339658      Patent   \n",
       "\n",
       "                                                                                                                                    paper_title  \\\n",
       "57                                                        counterfactual reward modification for streaming recommendation with delayed feedback   \n",
       "234                                                                                                                   stably fixed rubber frame   \n",
       "0                                                            applicability of magnetic resonance imaging of the knee in forensic age estimation   \n",
       "260                                    crystal lattice properties fully determine short range interaction parameters for alkali and halide ions   \n",
       "191                                                                     signal power lightning prevention box air switch state detecting system   \n",
       "94                                                                                                ionic transport in high energy density matter   \n",
       "19                         pengaruh faktor faktor budaya organisasi terhadap kinerja karyawan pt wonokoyo jaya corporindo kantor pusat surabaya   \n",
       "39                         differences in health seeking behaviors by socioeconomic groups among the pediatric hydrocephalus patient population   \n",
       "30                insuline bagimli diabetes mellituslu hastalarda hbaic ile serum insulin kolesterol ve trigliserit duzeyleri arasindaki iliski   \n",
       "113                                                                     comparative study of belt loop gastropexy and fundic gastropexy in dogs   \n",
       "4                                                                                      observations of split shear waves from young ocean crust   \n",
       "1    discussion of cylindrical central baffle flume for flow measurement in open channels by aniruddha d ghare ankur kapoor and avinash m badar   \n",
       "230                                                              liquid nitrogen refrigerator truck with thermoelectric power generation device   \n",
       "251                                         target delineation for radiosurgery including postoperative cavity radiosurgery in brain metastases   \n",
       "90                                                                     maternal exposure to cooking smoke and risk of low birth weight in india   \n",
       "170                                              modification of silicone elastomer with zwitterionic silane for durable antifouling properties   \n",
       "38                                   fraxinellone alleviates kidney fibrosis by inhibiting cug binding protein 1 mediated fibroblast activation   \n",
       "78                                 study on anisotropic mechanical properties and failure modes of layered rock using uniaxial compression test   \n",
       "93                             development of octacalcium phosphate bone substitute material and its elucidation of osteoconductivity mechanism   \n",
       "276                                                                                              magnetic stirring device for tissue dehydrator   \n",
       "\n",
       "                                            journal_name publication_date  \\\n",
       "57                                                  None       2021-07-11   \n",
       "234                                                 None       2020-05-19   \n",
       "0    american journal of forensic medicine and pathology       2021-06-01   \n",
       "260                          journal of chemical physics       2012-08-09   \n",
       "191                                                 None       2017-11-24   \n",
       "94             bulletin of the american physical society       2015-11-17   \n",
       "19                                                  None       2008-01-01   \n",
       "39                        interdisciplinary neurosurgery       2021-06-01   \n",
       "30              turkiye klinikleri tip bilimleri dergisi       1994-01-01   \n",
       "113                                                 None       1994-11-01   \n",
       "4                                                   None       1991-01-01   \n",
       "1    journal of irrigation and drainage engineering asce       2021-07-01   \n",
       "230                                                 None       2019-06-21   \n",
       "251                                                 None       2020-01-01   \n",
       "90                      science of the total environment       2021-06-20   \n",
       "170                                                 None       2017-01-01   \n",
       "38                   toxicology and applied pharmacology       2021-06-01   \n",
       "78                     journal of testing and evaluation       2021-09-01   \n",
       "93         frontiers in bioengineering and biotechnology       2016-01-01   \n",
       "276                                                 None       2020-05-05   \n",
       "\n",
       "                                                                                                                                                                                                             topics  \n",
       "57                                                                                                                                                [computer science, counterfactual thinking, cognitive psychology]  \n",
       "234                                                                             [vertical edge, integrally closed, geometry, natural rubber, perpendicular, limiting, edge, physics, liquid crystal display, frame]  \n",
       "0                                                       [stage, magnetic resonance imaging, radiology, radiological weapon, ossification, age estimation, femoral epiphysis, forensic science, medicine, mri image]  \n",
       "260                                                  [lennard jones potential, ion, lattice energy, materials science, lattice, lattice constant, aqueous solution, chemical physics, solvation, crystal structure]  \n",
       "191                                                                                          [electricity, interface, power, signal, state, electrical engineering, logic gate, lightning, computer science, alarm]  \n",
       "94                                        [boltzmann constant, coulomb, statistical physics, high energy density matter, thermal conductivity, yukawa potential, viscosity, molecular dynamics, physics, logarithm]  \n",
       "19   [statistical significance, business administration, competence, employee performance, linear regression, operations management, competitive advantage, strategic management, engineering, teamwork, variables]  \n",
       "39                                     [pediatrics, medicine, socioeconomic status, vomiting, pediatric hydrocephalus, patient population, household income, hydrocephalus, health seeking, descriptive statistics]  \n",
       "30                                                                                                                                                                                                       [medicine]  \n",
       "113                                                                                                                                                                  [gastropexy, mathematics, anatomy, null, loop]  \n",
       "4                                                                      [geophysics, ocean bottom seismometer, polarization, seismic anisotropy, shear waves, magnetosphere particle motion, oceanic crust, geology]  \n",
       "1                                                                                                                                                             [flume, baffle, geology, mechanics, flow measurement]  \n",
       "230                                                [thermoelectric generator, liquid nitrogen, pressure regulator, refrigerator car, exhaust gas, atmosphere, truck, waste management, nitrogen, materials science]  \n",
       "251                                                         [radiology, computed tomography, contouring, mri techniques, radiation therapy, magnetic resonance imaging, spatial distortion, radiosurgery, medicine]  \n",
       "90                                                                                            [family health, environmental health, smoke, cooking practices, medicine, low birth weight, birth weight, birth size]  \n",
       "170                                                                                                                                [silicone, elastomer, silane, materials science, biofouling, composite material]  \n",
       "38                                 [kidney fibrosis, medicine, fraxinellone, pharmacology, cyclin dependent kinase, cug binding protein, kidney, fibroblast, kidney disease, p38 mitogen activated protein kinases]  \n",
       "78                    [failure mode and effects analysis, ultimate tensile strength, composite material, bedding, materials science, shearing, compressive strength, magnetic dip, transverse isotropy, anisotropy]  \n",
       "93                                                                                                                                       [biophysics, octacalcium phosphate, mechanism, chemistry, bone substitute]  \n",
       "276                                                                                                                        [magnetic field, base, materials science, cylinder, bearing, composite material, magnet]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_raw.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_raw.to_parquet(\"test_raw.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting Everything Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(data, target_col, predict_col):\n",
    "    targets = tf.keras.preprocessing.sequence.pad_sequences(data[target_col].to_list(), maxlen=20, \n",
    "                                                            dtype='int64', padding='post', \n",
    "                                                            truncating='post', value=0)\n",
    "    targets = tf.RaggedTensor.from_tensor(targets, padding=0)\n",
    "    targets = encoding_layer(targets)\n",
    "    \n",
    "    predictions = tf.keras.preprocessing.sequence.pad_sequences(data[predict_col].to_list(), maxlen=30, \n",
    "                                                                dtype='int64', padding='post', \n",
    "                                                                truncating='post', value=0)\n",
    "    predictions = tf.RaggedTensor.from_tensor(predictions, padding=0)\n",
    "    predictions = encoding_layer(predictions)\n",
    "    \n",
    "    recall_score = tf.keras.metrics.Recall()\n",
    "    precision_score = tf.keras.metrics.Precision()\n",
    "    \n",
    "    recall_score.update_state(targets,predictions)\n",
    "    precision_score.update_state(targets,predictions)\n",
    "    \n",
    "    print(f\"Recall: {round(recall_score.result().numpy()*100, 1)}%\")\n",
    "    print(f\"Precision: {round(precision_score.result().numpy()*100, 1)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(test_data, 'target_tok', 'predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Sample of Targets vs Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_data = test_data.sample(10)\n",
    "for i,j in zip(sample_data['target_tok'].to_list(),sample_data['predictions'].to_list()):\n",
    "    print(\"Targets:\")\n",
    "    print([target_vocab_inv.get(x) for x in i])\n",
    "    print(\"\\n\")\n",
    "    print(\"Predictions:\")\n",
    "    print([target_vocab_inv.get(x) for x in j])\n",
    "    print(\"-----------------------------------------------------------------------------\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,j in target_vocab_inv.items():\n",
    "    if i < 50:\n",
    "        print(f\"{i}: {j}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_ones = [2,3,4,5,6,7,11,12,13,14,16,18,19,21,24,29,32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get metrics for different levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to get df that contains the tag and the appropriate level (get only tags that show up in vocab)\n",
    "# also need to match up the tag with the tag_id from the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels_df = pd.read_parquet(\"./test_data_files/tag_levels.parquet\").fillna(6)\n",
    "levels_df['level'] = levels_df['level'].astype('int')\n",
    "# levels_df = pd.DataFrame(zip(level_ones, [1]*len(level_ones)), columns=['tag','level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels_df['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_for_specific_level(old_df, levels, level_to_get=1):\n",
    "    df = old_df.copy()\n",
    "    tags_list = levels[levels['level']==level_to_get]['topic_name'].to_list()\n",
    "    tags_id_list = [target_vocab.get(x) for x in tags_list]\n",
    "    print(f\"Number of Level {level_to_get} Tags: {len(tags_list)}\")\n",
    "    \n",
    "    df[f'tags_level_{level_to_get}'] = df['target_tok'].apply(lambda x: [i for i in x if i in tags_id_list])\n",
    "    df[f'preds_level_{level_to_get}'] = df['predictions'].apply(lambda x: [i for i in x if i in tags_id_list])\n",
    "    \n",
    "    df[f'tag_level_{level_to_get}_len'] = df[f'tags_level_{level_to_get}'].apply(len)\n",
    "    df[f'pred_level_{level_to_get}_len'] = df[f'preds_level_{level_to_get}'].apply(len)\n",
    "    \n",
    "    papers_with_tag = (df[df[f'tag_level_{level_to_get}_len'] > 0].shape[0])/df.shape[0]\n",
    "    papers_with_pred = (df[df[f'pred_level_{level_to_get}_len'] > 0].shape[0])/df.shape[0]\n",
    "    \n",
    "    print(f\"Percentage of papers with Level {level_to_get} Tags: {round(papers_with_tag*100, 1)}\")\n",
    "    print(f\"Percentage of papers with Level {level_to_get} Preds: {round(papers_with_pred*100, 1)}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_to_check = 0\n",
    "df = get_df_for_specific_level(test_data, levels_df, level_to_check)\n",
    "get_metrics(df, f\"tags_level_{level_to_check}\", f\"preds_level_{level_to_check}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_to_check = 1\n",
    "df = get_df_for_specific_level(test_data, levels_df, level_to_check)\n",
    "get_metrics(df, f\"tags_level_{level_to_check}\", f\"preds_level_{level_to_check}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_to_check = 2\n",
    "df = get_df_for_specific_level(test_data, levels_df, level_to_check)\n",
    "get_metrics(df, f\"tags_level_{level_to_check}\", f\"preds_level_{level_to_check}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_to_check = 3\n",
    "df = get_df_for_specific_level(test_data, levels_df, level_to_check)\n",
    "get_metrics(df, f\"tags_level_{level_to_check}\", f\"preds_level_{level_to_check}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_to_check = 4\n",
    "df = get_df_for_specific_level(test_data, levels_df, level_to_check)\n",
    "get_metrics(df, f\"tags_level_{level_to_check}\", f\"preds_level_{level_to_check}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_to_check = 5\n",
    "df = get_df_for_specific_level(test_data, levels_df, level_to_check)\n",
    "get_metrics(df, f\"tags_level_{level_to_check}\", f\"preds_level_{level_to_check}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_to_check = 6\n",
    "df = get_df_for_specific_level(test_data, levels_df, level_to_check)\n",
    "get_metrics(df, f\"tags_level_{level_to_check}\", f\"preds_level_{level_to_check}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking into Data Available vs Not Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['journal'] = test_data['journal_tok'].apply(lambda x: [journal_vocab_inv.get(i) for i in x][0])\n",
    "test_data['doc_type'] = test_data['doc_type_tok'].apply(lambda x: [doc_vocab_inv.get(i) for i in x][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>doc_type_tok</th>\n",
       "      <th>journal_tok</th>\n",
       "      <th>target_tok</th>\n",
       "      <th>paper_title_tok</th>\n",
       "      <th>paper_title_mask</th>\n",
       "      <th>predictions</th>\n",
       "      <th>scores</th>\n",
       "      <th>journal</th>\n",
       "      <th>doc_type</th>\n",
       "      <th>paper_title_tok_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16657</th>\n",
       "      <td>2604922879</td>\n",
       "      <td>2001-11-28</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[2, 2494, 5036, 43, 2373, 2110, 203, 14923, 10...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4, 2, 157, 87, 78, 10, 28, 286, 167, 339, 48,...</td>\n",
       "      <td>[0.6048187017440796, 0.3559792637825012, 0.291...</td>\n",
       "      <td>[NONE]</td>\n",
       "      <td>Patent</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         paper_id publication_date doc_type_tok journal_tok target_tok  \\\n",
       "16657  2604922879       2001-11-28          [4]         [2]        [2]   \n",
       "\n",
       "                                         paper_title_tok  \\\n",
       "16657  [2, 2494, 5036, 43, 2373, 2110, 203, 14923, 10...   \n",
       "\n",
       "                                        paper_title_mask  \\\n",
       "16657  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                             predictions  \\\n",
       "16657  [4, 2, 157, 87, 78, 10, 28, 286, 167, 339, 48,...   \n",
       "\n",
       "                                                  scores journal doc_type  \\\n",
       "16657  [0.6048187017440796, 0.3559792637825012, 0.291...  [NONE]   Patent   \n",
       "\n",
       "       paper_title_tok_len  \n",
       "16657                   47  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Journal', 'Patent', '[NONE]', 'Conference', 'Repository', 'Thesis',\n",
       "       'Book', 'BookChapter'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['doc_type'].value_counts().index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Different Doc Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Journal\n",
      "Recall: 49.2%\n",
      "Precision: 27.9%\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Patent\n",
      "Recall: 48.3%\n",
      "Precision: 24.3%\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "[NONE]\n",
      "Recall: 51.5%\n",
      "Precision: 21.0%\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Conference\n",
      "Recall: 45.7%\n",
      "Precision: 28.6%\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Repository\n",
      "Recall: 45.7%\n",
      "Precision: 25.8%\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Thesis\n",
      "Recall: 52.6%\n",
      "Precision: 24.1%\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Book\n",
      "Recall: 57.6%\n",
      "Precision: 20.7%\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "BookChapter\n",
      "Recall: 68.4%\n",
      "Precision: 17.3%\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc_type in test_data['doc_type'].value_counts().index:\n",
    "    print(doc_type)\n",
    "    get_metrics(test_data[test_data['doc_type']==doc_type], \"target_tok\", \"predictions\")\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_input_single.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json = json.dumps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"title\": \"applicability of magnetic resonance imaging of the knee in forensic age estimation\", \"doc_type\": \"Journal\", \"journal\": \"american journal of forensic medicine and pathology\"}]'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.read_json(input_json, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>doc_type</th>\n",
       "      <th>journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>applicability of magnetic resonance imaging of the knee in forensic age estimation</td>\n",
       "      <td>Journal</td>\n",
       "      <td>american journal of forensic medicine and pathology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                title  \\\n",
       "0  applicability of magnetic resonance imaging of the knee in forensic age estimation   \n",
       "\n",
       "  doc_type                                              journal  \n",
       "0  Journal  american journal of forensic medicine and pathology  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_layer = tf.keras.layers.experimental.preprocessing.CategoryEncoding(\n",
    "    max_tokens=len(target_vocab)+1, output_mode=\"binary\", sparse=False)\n",
    "\n",
    "# Load the model components\n",
    "raw_model = tf.keras.models.load_model(f'./{model_iteration}/models/gamma28_nH8_nL6_epoch20/', compile=False)\n",
    "\n",
    "raw_model.trainable = False\n",
    "\n",
    "mag_model = tf.keras.Model(inputs=raw_model.inputs, \n",
    "                           outputs=tf.math.top_k(raw_model.outputs, k=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_feature(feature, feature_name='doc_type'):\n",
    "    if feature_name=='doc_type':\n",
    "        vocab = doc_vocab\n",
    "    else:\n",
    "        vocab = journal_vocab\n",
    "    unk_token_id = vocab.get('[UNK]')\n",
    "    none_token_id = vocab.get('[NONE]')\n",
    "    if feature:\n",
    "        token_feature = [vocab.get(feature, unk_token_id)]\n",
    "    else:\n",
    "        token_feature = [none_token_id]\n",
    "    return token_feature\n",
    "\n",
    "def tokenize_title(feature):\n",
    "    split_feature = feature.split(\" \")\n",
    "    vocab = title_vocab\n",
    "    unk_token_id = vocab.get('[UNK]')\n",
    "    none_token_id = vocab.get('[NONE]')\n",
    "    if feature:\n",
    "        token_feature = [vocab.get(x, unk_token_id) for x in split_feature]\n",
    "    else:\n",
    "        token_feature = [none_token_id]\n",
    "    return token_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['title'] = input_df['title'].apply(lambda x: x.lower().strip())\n",
    "input_df['paper_title_tok'] = input_df['title'].apply(tokenize_title)\n",
    "input_df['doc_type_tok'] = input_df['doc_type'].apply(tokenize_feature, args=('doc_type',))\n",
    "input_df['journal_tok'] = input_df['journal'].apply(tokenize_feature, args=('journal',))\n",
    "\n",
    "paper_titles = tf.keras.preprocessing.sequence.pad_sequences(input_df['paper_title_tok'].to_list(), maxlen=64, \n",
    "                                                         dtype='int64', padding='post', \n",
    "                                                         truncating='post', value=0)\n",
    "\n",
    "doc_types = tf.convert_to_tensor(input_df['doc_type_tok'].to_list())\n",
    "journal = tf.convert_to_tensor(input_df['journal_tok'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 32756, 126553, 151326,  59379, 131238, 126553,  97706,  37472,\n",
       "         39795,  97769, 103059, 118852,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[3]], dtype=int32)>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[4892]], dtype=int32)>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = mag_model([paper_titles, doc_types, journal])\n",
    "    \n",
    "scores = model_output.values.numpy()[0].tolist()\n",
    "preds = model_output.indices.numpy()[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = []\n",
    "for score, pred in zip(scores, preds):\n",
    "    tags = []\n",
    "    for i in range(25):\n",
    "        if score[i] >= 0.35:\n",
    "            tags.append(target_vocab_inv.get(pred[i]))\n",
    "    all_tags.append({\"tags\": tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tags': ['medicine',\n",
       "   'magnetic resonance imaging',\n",
       "   'nuclear medicine',\n",
       "   'forensic anthropology',\n",
       "   'radiology']}]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"tags\": [\"medicine\", \"magnetic resonance imaging\", \"nuclear medicine\", \"forensic anthropology\", \"radiology\"]}]'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "mag_model_baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
